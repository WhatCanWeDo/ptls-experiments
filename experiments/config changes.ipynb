{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "7c140a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scenario_alpha_battle/conf/mles_params.yaml',\n",
       " 'scenario_alpha_battle/conf/random_params.yaml',\n",
       " 'scenario_alpha_battle/conf/agg_features_params.yaml',\n",
       " 'scenario_alpha_battle/conf/embeddings_validation.yaml',\n",
       " 'scenario_alpha_battle/conf/rtd_params.yaml',\n",
       " 'scenario_alpha_battle/conf/nsp_params.yaml',\n",
       " 'scenario_alpha_battle/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_alpha_battle/conf/cpc_params.yaml',\n",
       " 'scenario_alpha_battle/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_alpha_battle/conf/sop_params.yaml',\n",
       " 'scenario_alpha_battle/conf/barlow_twins_params.yaml',\n",
       " 'scenario_alpha_battle/conf/dataset_inference_file.yaml',\n",
       " 'scenario_bowl2019/conf/pl_fit_target.yaml',\n",
       " 'scenario_bowl2019/conf/mles_params.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_v2_params.yaml',\n",
       " 'scenario_bowl2019/conf/random_params.yaml',\n",
       " 'scenario_bowl2019/conf/agg_features_params.yaml',\n",
       " 'scenario_bowl2019/conf/embeddings_validation.yaml',\n",
       " 'scenario_bowl2019/conf/rtd_params.yaml',\n",
       " 'scenario_bowl2019/conf/pl_fit_finetuning_barlow_twins.yaml',\n",
       " 'scenario_bowl2019/conf/nsp_params.yaml',\n",
       " 'scenario_bowl2019/conf/embeddings_validation_semi_supervised.yaml',\n",
       " 'scenario_bowl2019/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_params_for_finetuning.yaml',\n",
       " 'scenario_bowl2019/conf/pl_fit_finetuning_cpc.yaml',\n",
       " 'scenario_bowl2019/conf/pl_fit_finetuning_mles.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_v2_pl_fit_finetuning.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_params.yaml',\n",
       " 'scenario_bowl2019/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_bowl2019/conf/sop_params.yaml',\n",
       " 'scenario_bowl2019/conf/barlow_twins_params.yaml',\n",
       " 'scenario_bowl2019/conf/dataset_inference_file.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_v2_embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_bowl2019/conf/embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_bowl2019/conf/cpc_v2_embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_bowl2019/conf/trx_dataset.yaml',\n",
       " 'scenario_bowl2019/conf/pl_fit_finetuning_rtd.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_target.yaml',\n",
       " 'scenario_rosbank/conf/mles_params.yaml',\n",
       " 'scenario_rosbank/conf/random_params.yaml',\n",
       " 'scenario_rosbank/conf/agg_features_params.yaml',\n",
       " 'scenario_rosbank/conf/embeddings_validation.yaml',\n",
       " 'scenario_rosbank/conf/rtd_params.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_finetuning_barlow_twins.yaml',\n",
       " 'scenario_rosbank/conf/nsp_params.yaml',\n",
       " 'scenario_rosbank/conf/embeddings_validation_semi_supervised.yaml',\n",
       " 'scenario_rosbank/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_rosbank/conf/mles_proj_head_params.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_finetuning_cpc.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_finetuning_mles.yaml',\n",
       " 'scenario_rosbank/conf/cpc_params.yaml',\n",
       " 'scenario_rosbank/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_rosbank/conf/sop_params.yaml',\n",
       " 'scenario_rosbank/conf/barlow_twins_params.yaml',\n",
       " 'scenario_rosbank/conf/dataset.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_finetuning_nsp.yaml',\n",
       " 'scenario_rosbank/conf/dataset_inference_file.yaml',\n",
       " 'scenario_rosbank/conf/embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_rosbank/conf/pl_fit_finetuning_rtd.yaml',\n",
       " 'scenario_gender/conf/pl_fit_target.yaml',\n",
       " 'scenario_gender/conf/mles_params.yaml',\n",
       " 'scenario_gender/conf/cpc_v2_params.yaml',\n",
       " 'scenario_gender/conf/dataset_map_file.yaml',\n",
       " 'scenario_gender/conf/random_params.yaml',\n",
       " 'scenario_gender/conf/agg_features_params.yaml',\n",
       " 'scenario_gender/conf/pl_fit_distribution_target_statistics.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation.yaml',\n",
       " 'scenario_gender/conf/rtd_params.yaml',\n",
       " 'scenario_gender/conf/pl_fit_finetuning_barlow_twins.yaml',\n",
       " 'scenario_gender/conf/nsp_params.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation_semi_supervised.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_gender/conf/mles_proj_head_params.yaml',\n",
       " 'scenario_gender/conf/dataset_iterable_file.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation_distribution_target.yaml',\n",
       " 'scenario_gender/conf/pl_fit_finetuning_cpc.yaml',\n",
       " 'scenario_gender/conf/pl_fit_finetuning_mles.yaml',\n",
       " 'scenario_gender/conf/pl_fit_distribution_target_agg_features.yaml',\n",
       " 'scenario_gender/conf/cpc_v2_pl_fit_finetuning.yaml',\n",
       " 'scenario_gender/conf/cpc_params.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_gender/conf/sop_params.yaml',\n",
       " 'scenario_gender/conf/emb_valid.yaml',\n",
       " 'scenario_gender/conf/barlow_twins_params.yaml',\n",
       " 'scenario_gender/conf/dataset.yaml',\n",
       " 'scenario_gender/conf/pl_fit_distribution_target.yaml',\n",
       " 'scenario_gender/conf/dataset_inference_file.yaml',\n",
       " 'scenario_gender/conf/cpc_v2_embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_gender/conf/embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_gender/conf/cpc_v2_embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_gender/conf/pl_fit_finetuning_rtd.yaml',\n",
       " 'scenario_age_pred/conf/dataset_iterable_part.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_target.yaml',\n",
       " 'scenario_age_pred/conf/mles_params.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_finetuning_on_transf_params.yaml',\n",
       " 'scenario_age_pred/conf/dataset_map_file.yaml',\n",
       " 'scenario_age_pred/conf/random_params.yaml',\n",
       " 'scenario_age_pred/conf/agg_features_params.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_distribution_target_statistics.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation.yaml',\n",
       " 'scenario_age_pred/conf/rtd_params.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_finetuning_barlow_twins.yaml',\n",
       " 'scenario_age_pred/conf/dataset_map_part.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_transformer.yaml',\n",
       " 'scenario_age_pred/conf/nsp_params.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_semi_supervised.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_age_pred/conf/mles_proj_head_params.yaml',\n",
       " 'scenario_age_pred/conf/dataset_iterable_file.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_distribution_target.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_finetuning_cpc.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_finetuning_mles.yaml',\n",
       " 'scenario_age_pred/conf/cpc_params.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_age_pred/conf/sop_params.yaml',\n",
       " 'scenario_age_pred/conf/mles_params_for_finetuning.yaml',\n",
       " 'scenario_age_pred/conf/barlow_twins_params.yaml',\n",
       " 'scenario_age_pred/conf/transformer_params.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_distribution_target.yaml',\n",
       " 'scenario_age_pred/conf/dataset_inference_file.yaml',\n",
       " 'scenario_age_pred/conf/embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_age_pred/conf/pl_fit_finetuning_rtd.yaml',\n",
       " 'scenario_x5/conf/pl_fit_finetuning_on_rtd.yaml',\n",
       " 'scenario_x5/conf/pl_fit_finetuning_on_barlow_twins.yaml',\n",
       " 'scenario_x5/conf/mles_params.yaml',\n",
       " 'scenario_x5/conf/pl_fit_finetuning_on_cpc.yaml',\n",
       " 'scenario_x5/conf/random_params.yaml',\n",
       " 'scenario_x5/conf/agg_features_params.yaml',\n",
       " 'scenario_x5/conf/embeddings_validation.yaml',\n",
       " 'scenario_x5/conf/rtd_params.yaml',\n",
       " 'scenario_x5/conf/nsp_params.yaml',\n",
       " 'scenario_x5/conf/embeddings_validation_semi_supervised.yaml',\n",
       " 'scenario_x5/conf/embeddings_validation_baselines_unsupervised.yaml',\n",
       " 'scenario_x5/conf/rtd_params_for_finetuning.yaml',\n",
       " 'scenario_x5/conf/pl_fit_finetuning_on_mles.yaml',\n",
       " 'scenario_x5/conf/cpc_params.yaml',\n",
       " 'scenario_x5/conf/embeddings_validation_short.yaml',\n",
       " 'scenario_x5/conf/sop_params.yaml',\n",
       " 'scenario_x5/conf/mles_params_for_finetuning.yaml',\n",
       " 'scenario_x5/conf/barlow_twins_params.yaml',\n",
       " 'scenario_x5/conf/dataset.yaml',\n",
       " 'scenario_x5/conf/dataset_inference_file.yaml',\n",
       " 'scenario_x5/conf/embeddings_validation_baselines_supervised.yaml',\n",
       " 'scenario_x5/conf/pl_fit_target_rnn.yaml']"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob('*/conf/*.yaml')\n",
    "print(len(files))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a8db3",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "1) trx_encoder block shifted 2 spaces right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ff99bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = 'scenario_age_pred/conf/test.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ef553b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    for ix, line in enumerate(lines):\n",
    "        if start and line[4] != ' ' and not (line[:13] == '    positions' or\n",
    "                                             line[:14] == '    embeddings' or\n",
    "                                             line[:18] == '    numeric_values' or\n",
    "                                             line[:19] == '    norm_embeddings' or\n",
    "                                             line[:20] == '    embeddings_noise' or\n",
    "                                             line[:22] == '    clip_replace_value' or\n",
    "                                             line[:28] == '    use_batch_norm_with_lens'):\n",
    "#             print(line)\n",
    "            start = False\n",
    "            \n",
    "        if line[:14] == '  trx_encoder:':\n",
    "            lines[ix] = '  {l}'.format(l=line)\n",
    "            start = True\n",
    "        elif start:\n",
    "            lines[ix] = '  {l}'.format(l=line)\n",
    "            changed = True\n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711c160",
   "metadata": {},
   "source": [
    "2) add target to trxencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "6b7a6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "all_files.remove('scenario_age_pred/conf/mles_params.yaml')\n",
    "all_files.remove('scenario_age_pred/conf/cpc_params.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for ix, line in enumerate(lines):\n",
    "        if line[:16] == '    trx_encoder:':\n",
    "            lines.insert(ix + 1, '      _target_: ptls.trx_encoder.TrxEncoder\\n')\n",
    "            cnt += 1\n",
    "            break\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c5b18",
   "metadata": {},
   "source": [
    "3) encoder_type -> seq_encoder + _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "da3ced25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg_features',\n",
       " 'distribution_targets',\n",
       " 'emb_valid',\n",
       " 'pretrained',\n",
       " 'rnn',\n",
       " 'statistics',\n",
       " 'transf'}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "all_encoder_types = set()\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    for ix, line in enumerate(lines):\n",
    "        if line.find('encoder_type') != -1:\n",
    "            ix = line.find(':')\n",
    "            type_name = line[ix + 2: -1]\n",
    "            all_encoder_types.add(type_name)\n",
    "\n",
    "        \n",
    "all_encoder_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "732dbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'agg_features': 'ptls.seq_encoder.rnn_encoder.AggFeatureSeqEncoder',\n",
    "     'rnn': 'ptls.seq_encoder.rnn_encoder.RnnSeqEncoder',\n",
    "     'distribution_targets': 'ptls.seq_to_target.SequenceToTarget',\n",
    "     'emb_valid': 'ptls.seq_encoder.dummy_encoder.DummyEncoder',\n",
    "     'statistics': 'ptls.seq_encoder.statistics_encoder.StatisticsEncoder',\n",
    "     'transf': 'ptls.seq_encoder.transf_seq_encoder.TransfSeqEncoder'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "426acd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    start = False\n",
    "    for i, line in enumerate(lines):\n",
    "        enc_type_ix = line.find('encoder_type')\n",
    "        if enc_type_ix != -1:\n",
    "            ix = line.find(':')\n",
    "            type_name = line[ix + 2: -1]\n",
    "            if type_name != 'pretrained':\n",
    "                lines[i] = ' ' * enc_type_ix + 'seq_encoder:\\n'\n",
    "                lines.insert(i + 1, ' ' * enc_type_ix + f'  _target_: {m[type_name]}\\n')\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40e299",
   "metadata": {},
   "source": [
    "### Both rnn: and transf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "c197d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario_alpha_battle/conf/mles_params.yaml\n",
      "scenario_alpha_battle/conf/barlow_twins_params.yaml\n",
      "scenario_age_pred/conf/mles_params_for_finetuning.yaml\n",
      "scenario_x5/conf/mles_params.yaml\n",
      "scenario_x5/conf/mles_params_for_finetuning.yaml\n",
      "scenario_x5/conf/barlow_twins_params.yaml\n",
      "6 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    rnn_found = transf_found = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.find('rnn:') != -1:\n",
    "            rnn_found = True\n",
    "        if line.find('transf:') != -1:\n",
    "            transf_found = True\n",
    "    if rnn_found and transf_found:\n",
    "        cnt += 1\n",
    "        print(config_fname)\n",
    "\n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e36d2e",
   "metadata": {},
   "source": [
    "### Delete transf: block where rnn: is presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "e699aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files changed\n"
     ]
    }
   ],
   "source": [
    "both_files = ['scenario_alpha_battle/conf/mles_params.yaml',\n",
    "              'scenario_alpha_battle/conf/barlow_twins_params.yaml',\n",
    "              'scenario_age_pred/conf/mles_params_for_finetuning.yaml',\n",
    "              'scenario_x5/conf/mles_params.yaml',\n",
    "              'scenario_x5/conf/mles_params_for_finetuning.yaml',\n",
    "              'scenario_x5/conf/barlow_twins_params.yaml']\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = both_files\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    yyy = 0\n",
    "    start_ix = None\n",
    "    start_trx = False\n",
    "    start_trx_ix = None\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('transf:')\n",
    "        if ix != -1:\n",
    "            start_ix = ix\n",
    "            start = True\n",
    "            lines.pop(i + yyy)\n",
    "            yyy -= 1\n",
    "        elif start and line[start_ix] != ' ':\n",
    "            start = False\n",
    "            break\n",
    "        elif start:\n",
    "            nnn = line.find('trx_encoder:')\n",
    "            if start_trx or nnn != -1:\n",
    "                start_trx = True\n",
    "                lines[i + yyy] = line[2:]\n",
    "                continue\n",
    "            lines.pop(i + yyy)\n",
    "            yyy -= 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{len(both_files)} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17eb93d",
   "metadata": {},
   "source": [
    "4) remove rnn: and transf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "eab23127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.find('rnn:') != -1 or line.find('transf:') != -1:\n",
    "            lines.pop(i)\n",
    "            changed = True\n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144afa8",
   "metadata": {},
   "source": [
    "5) data_module_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "6f97e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.find('data_module_class:') != -1:\n",
    "            pos = line.find(':')\n",
    "            changed = True\n",
    "            data_module_class_name = line[pos + 2: -1]\n",
    "            lines.pop(i)\n",
    "            break\n",
    "    if changed:\n",
    "#         print(data_module_class_name)\n",
    "        cnt += 1\n",
    "    \n",
    "        for i, line in enumerate(lines):\n",
    "            ix = line.find('data_module:')\n",
    "            if ix != -1:\n",
    "                lines.insert(i + 1, ' ' * ix + f'  _target_: {data_module_class_name}\\n')\n",
    "                break\n",
    "\n",
    "                \n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8314de3",
   "metadata": {},
   "source": [
    "6) params -> pl_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "335c7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if line[:7] == 'params:':\n",
    "            lines[i] = 'pl_module:\\n'\n",
    "            changed = True\n",
    "            break\n",
    "    if changed:\n",
    "#         print(data_module_class_name)\n",
    "        cnt += 1\n",
    "          \n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b929ae",
   "metadata": {},
   "source": [
    "7) spaces before blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "a802eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "all_files.remove('scenario_age_pred/conf/mles_params.yaml')\n",
    "all_files.remove('scenario_age_pred/conf/cpc_params.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    ii = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        if line[0] != ' ' and i > 0:\n",
    "            lines.insert(i + ii, '\\n')\n",
    "            changed = True\n",
    "            ii += 1\n",
    "\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8fa93",
   "metadata": {},
   "source": [
    "8) handle pretrained_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "e382b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "all_params = set()\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    dd = {}\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pretrained:')\n",
    "        if ix != -1:\n",
    "            changed = start = True\n",
    "            found_start_ix = ix\n",
    "            continue\n",
    "        if start and line[found_start_ix] != ' ':\n",
    "            start = False\n",
    "        elif start:\n",
    "            dd[line[:line.find(':')].strip()] = line[line.find(':') + 2: -1]\n",
    "#             all_params.add(line[:line.find(':')].strip())\n",
    "#             print(line[line.find(':') + 2: -1])\n",
    "\n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    ii = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        if line[:10] == 'pl_module:' and 'model_path' in dd:\n",
    "            lines.insert(i + ii, f'pretrained_encoder_path: {dd[\"model_path\"]}\\n')\n",
    "            lines.insert(i + 1 + ii, f'pretrained_module_cls: {dd[\"pl_module_class\"]}\\n\\n')\n",
    "            ii += 3\n",
    "        \n",
    "        \n",
    "        ix = line.find('pretrained:')\n",
    "        if ix != -1:\n",
    "            changed = start = True\n",
    "            found_start_ix = ix\n",
    "            ii -= 1\n",
    "            lines.pop(i + ii)\n",
    "            continue\n",
    "        if start and line[found_start_ix] != ' ':\n",
    "            start = False\n",
    "            if 'lr' in dd:\n",
    "                lines.insert(i + ii - 1, ' ' * found_start_ix + f'pretrained_lr: {dd[\"lr\"]}\\n')\n",
    "        elif start:\n",
    "            ii -= 1\n",
    "            lines.pop(i + ii)\n",
    "                         \n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "7d5a4bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    ii = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        if line[:22] == 'pretrained_module_cls:':\n",
    "            changed = True\n",
    "            ixxx = line.find(':')\n",
    "            module_name = line[ixxx+2:-1]\n",
    "            lines[i] = 'pretrained_module_cls:\\n'\n",
    "            lines.insert(i + ii + 1, '  _target_: hydra.utils.get_class\\n')\n",
    "            lines.insert(i + ii + 2, f'  path: {module_name}\\n')\n",
    "            ii += 2\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "12fc75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    ii = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        if line.find('encoder_type: pretrained') != -1:\n",
    "            changed = True  \n",
    "            lines.pop(i + ii)\n",
    "            ii -= 1\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acffb62",
   "metadata": {},
   "source": [
    "9) pl_module_class -> _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "39d12bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module_class:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            pl_module_class_name = line[line.find(':') + 2: -1]\n",
    "            lines[i] = ' ' * ix + f'_target_: {pl_module_class_name}\\n'\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd0eba",
   "metadata": {},
   "source": [
    "10) _target_ for pl_files and score_metric -> metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "100c1d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('data_module:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines.insert(i + 1, '  _target_: ptls.data_load.data_module.cls_data_module.ClsDataModuleTrain\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "4a1751d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines.insert(i + 1, '  _target_: ptls.seq_to_target.SequenceToTarget\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "dfdc60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('score_metric: auroc')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines[i] = ' ' * ix + 'metric_list:\\n'\n",
    "            lines.insert(i + 1, '  - auroc\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "e4f94fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('score_metric: accuracy')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines[i] = ' ' * ix + 'metric_list:\\n'\n",
    "            lines.insert(i + 1, ' ' * ix + '  - accuracy\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "9446f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = glob.glob('*/conf/cpc_v2_pl_fit_finetuning.yaml')\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('score_metric:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines[i] = ' ' * ix + 'metric_list:\\n'\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "fbc54c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = glob.glob('*/conf/cpc_v2_pl_fit_finetuning.yaml')\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('pl_fit_') == -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    start_ix = None\n",
    "    yy = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('metric_list:')\n",
    "        if ix != -1:\n",
    "            start = True\n",
    "            start_ix = ix\n",
    "            continue\n",
    "        if start and line[start_ix] != ' ':\n",
    "            start = False\n",
    "        elif start:\n",
    "            changed = True\n",
    "            ff_ix = line.find('-')\n",
    "            if line.find('auroc') != -1:\n",
    "                lines[i + yy] = ' ' * ff_ix + 'auroc:\\n'\n",
    "                lines.insert(i + yy + 1, ' ' * (ff_ix + 2) + '_target_: torchmetrics.AUROC\\n')\n",
    "                lines.insert(i + yy + 2, ' ' * (ff_ix + 2) + 'num_classes: 2\\n')\n",
    "                lines.insert(i + yy + 3, ' ' * (ff_ix + 2) + 'compute_on_step: false\\n')\n",
    "                yy += 3\n",
    "            elif line.find('accuracy') != -1:\n",
    "                lines[i + yy] = ' ' * ff_ix + 'accuracy:\\n'\n",
    "                lines.insert(i + yy + 1, ' ' * (ff_ix + 2) + '_target_: torchmetrics.Accuracy\\n')\n",
    "                lines.insert(i + yy + 2, ' ' * (ff_ix + 2) + 'compute_on_step: false\\n')\n",
    "                yy += 2        \n",
    "            \n",
    "\n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6bb3b",
   "metadata": {},
   "source": [
    "11) remove 'score_metric' from other than pl_ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "fde9a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = glob.glob('*/conf/cpc_v2_pl_fit_finetuning.yaml')\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('score_metric:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines.pop(i)\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb826e",
   "metadata": {},
   "source": [
    "12) validation_metric_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "cc034ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = glob.glob('*/conf/cpc_v2_pl_fit_finetuning.yaml')\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('validation_metric_params:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines[i] = ' ' * ix + 'validation_metric:\\n'\n",
    "            lines.insert(i + 1, ' ' * (ix + 2) + '_target_: ptls.metric_learn.metric.BatchRecallTopPL\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7907b49",
   "metadata": {},
   "source": [
    "13) delete head block: from \n",
    "\n",
    "scenario_bowl2019/conf/pl_fit_target.yaml\n",
    "\n",
    "scenario_rosbank/conf/pl_fit_target.yaml\n",
    "\n",
    "scenario_bowl2019/conf/rtd_params.yaml\n",
    "\n",
    "scenario_rosbank/conf/rtd_params.yaml\n",
    "\n",
    "scenario_age_pred/conf/rtd_params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "0eefca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = ['scenario_age_pred/conf/test.test']\n",
    "all_files = ['scenario_bowl2019/conf/pl_fit_target.yaml',\n",
    "             'scenario_rosbank/conf/pl_fit_target.yaml',\n",
    "             'scenario_bowl2019/conf/rtd_params.yaml',\n",
    "             'scenario_rosbank/conf/rtd_params.yaml',\n",
    "             'scenario_age_pred/conf/rtd_params.yaml']\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    start_ix = None\n",
    "    yyy = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('head:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            start = True\n",
    "            start_ix = ix\n",
    "            lines.pop(i + yyy)\n",
    "            yyy -= 1\n",
    "        elif start and line[start_ix] != ' ':\n",
    "            start = False\n",
    "        elif start:\n",
    "            lines.pop(i + yyy)\n",
    "            yyy -= 1\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4f3a3",
   "metadata": {},
   "source": [
    "14) head_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "e833aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = ['scenario_age_pred/conf/test.test']\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "ff = 0\n",
    "for ix, el in enumerate(all_files.copy()):\n",
    "    if el.find('distribution_target') != -1 and el[el.rfind('/')+1:] != 'emb_valid.yaml':\n",
    "        all_files.pop(ix + ff)\n",
    "        ff -= 1\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    start_ix = None\n",
    "#     yyy = 0\n",
    "    in_head = {'BatchNorm1d': [False, None],\n",
    "               'NormEncoder': False,\n",
    "               'Linear': [False, None],\n",
    "               'LogSoftmax': [False, None],\n",
    "               'ReLU': False\n",
    "              }\n",
    "    candidates = None\n",
    "    current_main = None\n",
    "    yyy = 0\n",
    "    rnn = transf = False\n",
    "    input_size = None\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        if line.find('TransfSeqEncoder') != -1:\n",
    "            transf = True\n",
    "            input_size = '${pl_module.input_size}'\n",
    "        elif line.find('RnnSeqEncoder') != -1:\n",
    "            rnn = True\n",
    "            input_size = '${pl_module.hidden_size}'\n",
    "#         if rnn and line.find('hidden_size') != -1:\n",
    "#             input_size = line[line.find(':') + 2: -1]\n",
    "#         if transf and line.find('input_size') != -1:\n",
    "#             input_size = line[line.find(':') + 2: -1]\n",
    "            \n",
    "            \n",
    "        ix = line.find('head_layers:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            start = True\n",
    "            start_ix = ix\n",
    "#             lines[i + yyy] = ' ' * start_ix + 'head:\\n'\n",
    "#             lines.insert(i + yyy, ' ' * (start_ix + 2) + '_target_: ptls.models.Head\\n')\n",
    "#             yyy += 1\n",
    "        elif start and line[start_ix] != ' ':\n",
    "            start = False\n",
    "            break\n",
    "        elif start:\n",
    "            lines.pop(i + yyy)\n",
    "            yyy -= 1\n",
    "            \n",
    "            fl = False\n",
    "            for k, v in in_head.items():\n",
    "                if line.find(k) != -1:\n",
    "                    if k == 'BatchNorm1d':\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           'bias' not in in_head['Linear'][1]:\n",
    "                            in_head['Linear'][1]['bias'] = [True]\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           len(in_head['Linear'][1]['in_features']) > len(in_head['Linear'][1]['bias']):\n",
    "                            in_head['Linear'][1]['bias'] += [True]\n",
    "                            \n",
    "                        in_head['BatchNorm1d'][0] = True\n",
    "                        candidates = {'affine'}\n",
    "                        current_main = 'BatchNorm1d'\n",
    "                        fl = True\n",
    "                    elif k == 'NormEncoder':\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           'bias' not in in_head['Linear'][1]:\n",
    "                            in_head['Linear'][1]['bias'] = [True]\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           len(in_head['Linear'][1]['in_features']) > len(in_head['Linear'][1]['bias']):\n",
    "                            in_head['Linear'][1]['bias'] += [True]\n",
    "                            \n",
    "                        in_head['NormEncoder'] = True\n",
    "                        candidates = None\n",
    "                        current_main = 'NormEncoder'\n",
    "                        fl = True\n",
    "                    elif k == 'Linear':\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           'bias' not in in_head['Linear'][1]:\n",
    "                            in_head['Linear'][1]['bias'] = [True]\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           len(in_head['Linear'][1]['in_features']) > len(in_head['Linear'][1]['bias']):\n",
    "                            in_head['Linear'][1]['bias'] += [True]\n",
    "                            \n",
    "                        in_head['Linear'][0] = True\n",
    "                        candidates = {'in_features', 'out_features', 'bias'}\n",
    "                        current_main = 'Linear'\n",
    "                        fl = True\n",
    "                    elif k == 'LogSoftmax':\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           'bias' not in in_head['Linear'][1]:\n",
    "                            in_head['Linear'][1]['bias'] = [True]\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           len(in_head['Linear'][1]['in_features']) > len(in_head['Linear'][1]['bias']):\n",
    "                            in_head['Linear'][1]['bias'] += [True]\n",
    "                            \n",
    "                        in_head['LogSoftmax'][0] = True\n",
    "                        candidates = None\n",
    "                        current_main = 'LogSoftmax'\n",
    "                        fl = True\n",
    "                    elif k == 'ReLU':\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           'bias' not in in_head['Linear'][1]:\n",
    "                            in_head['Linear'][1]['bias'] = [True]\n",
    "                        if current_main == 'Linear' and \\\n",
    "                           len(in_head['Linear'][1]['in_features']) > len(in_head['Linear'][1]['bias']):\n",
    "                            in_head['Linear'][1]['bias'] += [True]\n",
    "                            \n",
    "                        in_head['ReLU'] = True\n",
    "                        candidates = None\n",
    "                        current_main = 'ReLU'\n",
    "                        fl = True \n",
    "            if fl: continue\n",
    "            \n",
    "            if not candidates: continue\n",
    "            for c in candidates:\n",
    "                if line.find(c) != -1:\n",
    "                    val = line[line.find(':') + 2: -1]\n",
    "                    if current_main == 'BatchNorm1d':\n",
    "                        in_head['BatchNorm1d'][1] = True\n",
    "                    elif current_main == 'Linear':\n",
    "                        if in_head['Linear'][1]:\n",
    "                            if c in in_head['Linear'][1]:\n",
    "                                in_head['Linear'][1][c] += [val]\n",
    "                            else:\n",
    "                                in_head['Linear'][1][c] = [val]\n",
    "                        else:\n",
    "                            in_head['Linear'][1] = {c: [val]}  \n",
    "            \n",
    "##########################################################################\n",
    "\n",
    "    changed = start = False\n",
    "    start_ix = None\n",
    "    yyy = 0\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('head_layers:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            start = True\n",
    "            start_ix = ix\n",
    "            lines[i] = ' ' * start_ix + 'head:\\n'\n",
    "            to_add = 1\n",
    "            lines.insert(i + to_add, ' ' * (start_ix + 2) + '_target_: ptls.models.Head\\n')\n",
    "            to_add += 1\n",
    "            if in_head['NormEncoder']:\n",
    "                lines.insert(i + to_add, ' ' * (start_ix + 2) + 'use_norm_encoder: true\\n')\n",
    "                to_add += 1\n",
    "            if input_size is None:\n",
    "                input_size = '777'\n",
    "            lines.insert(i + to_add, ' ' * (start_ix + 2) + f'input_size: {input_size}\\n')\n",
    "            to_add += 1            \n",
    "            if in_head['Linear'][0]:\n",
    "                hh = ', '.join(in_head['Linear'][1]['out_features'])\n",
    "                lines.insert(i + to_add, ' ' * (start_ix + 2) + f'hidden_layers_sizes: [{hh}]\\n')\n",
    "                to_add += 1\n",
    "#             if in_head['Linear'][1]['bias'][0] == 'false':\n",
    "#                 lines.insert(i + to_add, ' ' * (start_ix + 2) + 'linear_bias: false\\n')\n",
    "#                 to_add += 1\n",
    "            if in_head['BatchNorm1d'][0]:\n",
    "                lines.insert(i + to_add, ' ' * (start_ix + 2) + 'use_batch_norm: true\\n')\n",
    "                to_add += 1\n",
    "#             if in_head['BatchNorm1d'][1]:\n",
    "#                 lines.insert(i + to_add, ' ' * (start_ix + 2) + 'batch_norm_affine: false\\n')\n",
    "#                 to_add += 1\n",
    "            if in_head['LogSoftmax'][0]:\n",
    "                lines.insert(i + to_add, ' ' * (start_ix + 2) + 'objective: classification\\n')\n",
    "                lines.insert(i + to_add + 1, ' ' * (start_ix + 2) + 'num_classes: 4\\n')\n",
    "                to_add += 2\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "fd54ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm1d: num_features, affine\n",
    "# NormEncoder\n",
    "# Linear: in_features, out_features, bias\n",
    "# ReLU\n",
    "# LogSoftmax: dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf262a9",
   "metadata": {},
   "source": [
    "15) lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "76140643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = glob.glob('*/conf/cpc_v2_pl_fit_finetuning.yaml')\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "        \n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = False\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('lr_scheduler:')\n",
    "        if ix != -1:\n",
    "            changed = True\n",
    "            lines[i] = ' ' * ix + 'lr_scheduler_partial:\\n'\n",
    "            lines.insert(i + 1, ' ' * (ix + 2) + '_partial_: true\\n')\n",
    "            lines.insert(i + 2, ' ' * (ix + 2) + '_target_: torch.optim.lr_scheduler.StepLR\\n')\n",
    "            break\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0fb46",
   "metadata": {},
   "source": [
    "16) train block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "f24cfc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scenario_age_pred/conf/test.yaml'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "3a4d61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    lr_x = wd_x = None\n",
    "    ooo = 0\n",
    "    changed_xxx = start_xxx = False\n",
    "    found_start_ix_xxx = None\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module:')\n",
    "        if ix != -1:\n",
    "            start = True\n",
    "            found_start_ix = ix\n",
    "            continue\n",
    "#         if start and (len(line)<found_start_ix or line[found_start_ix] != ' '):\n",
    "#             start = False\n",
    "        if start:\n",
    "            ixxx = line.find('train:')\n",
    "            if ixxx != -1:\n",
    "                changed_xxx = start_xxx = True\n",
    "                found_start_ix_xxx = ixxx\n",
    "                continue\n",
    "            if start_xxx and (len(line) <= found_start_ix_xxx or line[found_start_ix_xxx] != ' '):\n",
    "                start = start_xxx = False\n",
    "                if lr_x or wd_x:\n",
    "                    changed = True\n",
    "                    lines.insert(i + ooo, ' '*found_start_ix_xxx + 'optimizer_partial:\\n')\n",
    "                    lines.insert(i + ooo + 1, ' '*(found_start_ix_xxx+2) + '_partial_: true\\n')\n",
    "                    lines.insert(i + ooo + 2, ' '*(found_start_ix_xxx+2) + '_target_: torch.optim.Adam\\n')\n",
    "                    ooo += 3\n",
    "                    if lr_x:\n",
    "                        lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + f'lr: {lr_x}\\n')\n",
    "                        ooo += 1\n",
    "                    if wd_x:\n",
    "                        lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + f'weight_decay: {wd_x}\\n')\n",
    "                        ooo += 1             \n",
    "            \n",
    "            elif start_xxx:\n",
    "                uu = line.find('lr:')\n",
    "                yy = line.find('weight_decay:')\n",
    "                if uu != -1:\n",
    "                    lr_x = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                if yy != -1:\n",
    "                    wd_x = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "b36526a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ContrastiveLoss(sampling_strategy(neg_count), margin),\n",
    "\n",
    "# BarlowTwinsLoss(sampling_strategy(neg_count), lambd),\n",
    "\n",
    "# bce,\n",
    "\n",
    "# NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "48de9aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    lr_x = wd_x = None\n",
    "    ooo = 0\n",
    "    changed_xxx = start_xxx = False\n",
    "    found_start_ix_xxx = None\n",
    "    sampling_strategy = neg_count = margin = lambd = None\n",
    "    \n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module:')\n",
    "        if ix != -1:\n",
    "            start = True\n",
    "            found_start_ix = ix\n",
    "            continue\n",
    "#         if start and (len(line)<found_start_ix or line[found_start_ix] != ' '):\n",
    "#             start = False\n",
    "        if start:\n",
    "            ixxx = line.find('train:')\n",
    "            if ixxx != -1:\n",
    "                changed_xxx = start_xxx = True\n",
    "                found_start_ix_xxx = ixxx\n",
    "                continue\n",
    "            if start_xxx and (len(line) <= found_start_ix_xxx or line[found_start_ix_xxx] != ' '):\n",
    "                start = start_xxx = False\n",
    "                if loss_name is not None:\n",
    "                    lines.insert(i + ooo, ' '*found_start_ix_xxx + 'loss:\\n')\n",
    "                    ooo += 1\n",
    "                    changed = True\n",
    "                if loss_name == 'ContrastiveLoss':\n",
    "                    lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + '_target_: ptls.metric_learn.losses.ContrastiveLoss\\n')\n",
    "                    lines.insert(i + ooo + 1, ' '*(found_start_ix_xxx+2) + f'margin: {margin}\\n')\n",
    "                    lines.insert(i + ooo + 2, ' '*(found_start_ix_xxx+2) + 'sampling_strategy:\\n')\n",
    "                    lines.insert(i + ooo + 3, ' '*(found_start_ix_xxx+4) + '_target_: ptls.metric_learn.sampling_strategies.HardNegativePairSelector\\n')\n",
    "                    lines.insert(i + ooo + 4, ' '*(found_start_ix_xxx+4) + f'neg_count: {neg_count}\\n')\n",
    "                    ooo += 5\n",
    "                elif loss_name == 'BarlowTwinsLoss':\n",
    "                    lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + '_target_: ptls.metric_learn.losses.BarlowTwinsLoss\\n')\n",
    "                    lines.insert(i + ooo + 1, ' '*(found_start_ix_xxx+2) + f'lambd: {lambd}\\n')\n",
    "                    lines.insert(i + ooo + 2, ' '*(found_start_ix_xxx+2) + 'sampling_strategy:\\n')\n",
    "                    lines.insert(i + ooo + 3, ' '*(found_start_ix_xxx+4) + '_target_: ptls.metric_learn.sampling_strategies.HardNegativePairSelector\\n')\n",
    "                    lines.insert(i + ooo + 4, ' '*(found_start_ix_xxx+4) + f'neg_count: {neg_count}\\n')\n",
    "                    ooo += 5\n",
    "                elif loss_name == 'bce':\n",
    "                    lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + '_target_: torch.nn.BCELoss\\n')\n",
    "                elif loss_name == 'NLLLoss':\n",
    "                    lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + '_target_: torch.nn.NLLLoss\\n')\n",
    "            \n",
    "            \n",
    "            elif start_xxx:\n",
    "                aa = line.find('loss:')\n",
    "                if aa != -1:\n",
    "                    loss_name = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                bb = line.find('sampling_strategy:')\n",
    "                if bb != -1:\n",
    "                    sampl_name = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                cc = line.find('neg_count:')\n",
    "                if cc != -1:\n",
    "                    neg_count = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                dd = line.find('margin:')\n",
    "                if dd != -1:\n",
    "                    margin = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                ee = line.find('lambd:')\n",
    "                if ee != -1:\n",
    "                    lambd = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "466178fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    lr_x = wd_x = None\n",
    "    ooo = 0\n",
    "    changed_xxx = start_xxx = False\n",
    "    found_start_ix_xxx = None\n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module:')\n",
    "        if ix != -1:\n",
    "            start = True\n",
    "            found_start_ix = ix\n",
    "            continue\n",
    "#         if start and (len(line)<found_start_ix or line[found_start_ix] != ' '):\n",
    "#             start = False\n",
    "        if start:\n",
    "            ixxx = line.find('train:')\n",
    "            if ixxx != -1:\n",
    "                changed_xxx = start_xxx = True\n",
    "                changed = True\n",
    "                found_start_ix_xxx = ixxx\n",
    "                lines.pop(i + ooo)\n",
    "                ooo -= 1\n",
    "                continue\n",
    "            if start_xxx and (len(line) <= found_start_ix_xxx or line[found_start_ix_xxx] != ' '):\n",
    "                start = start_xxx = False            \n",
    "            \n",
    "            elif start_xxx:\n",
    "                lines.pop(i + ooo)\n",
    "                ooo -= 1\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "d8fb3452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    found_start_ix = None\n",
    "    lr_x = wd_x = None\n",
    "    ooo = 0\n",
    "    changed_xxx = start_xxx = False\n",
    "    found_start_ix_xxx = None\n",
    "    n_forward_steps = n_negatives = None\n",
    "    \n",
    "    for i, line in enumerate(lines.copy()):\n",
    "        ix = line.find('pl_module:')\n",
    "        if ix != -1:\n",
    "            start = True\n",
    "            found_start_ix = ix\n",
    "            continue\n",
    "#         if start and (len(line)<found_start_ix or line[found_start_ix] != ' '):\n",
    "#             start = False\n",
    "        if start:\n",
    "            ixxx = line.find('cpc:')\n",
    "            if ixxx != -1:\n",
    "                changed_xxx = start_xxx = True\n",
    "                found_start_ix_xxx = ixxx\n",
    "                lines.pop(i + ooo)\n",
    "                ooo -= 1\n",
    "                continue\n",
    "            if start_xxx and (len(line) <= found_start_ix_xxx or line[found_start_ix_xxx] != ' '):\n",
    "                start = start_xxx = False\n",
    "                if loss_name is not None:\n",
    "                    lines.insert(i + ooo, ' '*found_start_ix_xxx + 'loss:\\n')\n",
    "                    ooo += 1\n",
    "                    changed = True\n",
    "                lines.insert(i + ooo, ' '*(found_start_ix_xxx+2) + '_target_: ptls.lightning_modules.cpc_module.CPC_Loss\\n')\n",
    "                lines.insert(i + ooo + 1, ' '*(found_start_ix_xxx+2) + f'n_forward_steps: {n_forward_steps}\\n')\n",
    "                lines.insert(i + ooo + 2, ' '*(found_start_ix_xxx+2) + f'n_negatives: {n_negatives}\\n')\n",
    "      \n",
    "            elif start_xxx:\n",
    "                aa = line.find('n_forward_steps:')\n",
    "                if aa != -1:\n",
    "                    n_forward_steps = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "                bb = line.find('n_negatives:')\n",
    "                if bb != -1:\n",
    "                    n_negatives = line[line.find(':') + 2: -1]\n",
    "                    lines.pop(i + ooo)\n",
    "                    ooo -= 1\n",
    "\n",
    "        \n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04efe37f",
   "metadata": {},
   "source": [
    "17) add _target_ to all pl_data_modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "69bce1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files changed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "# all_files = [test_file_name]\n",
    "all_files = glob.glob('*/conf/*.yaml')\n",
    "for config_fname in all_files:\n",
    "    with open(config_fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    changed = start = False\n",
    "    ooo = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.find('data_module:') != -1:\n",
    "            if lines[i + ooo + 1].find('_target_') == -1:\n",
    "                changed = True\n",
    "                lines.insert(i + ooo + 1, ' '*(line.find('data_module:')+2) + '_target_: ptls.data_load.data_module.cls_data_module.ClsDataModuleTrain\\n')\n",
    "                ooo += 1\n",
    "    if changed:\n",
    "        cnt += 1\n",
    "\n",
    "    with open(config_fname, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "print(f'{cnt} files changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02626cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
