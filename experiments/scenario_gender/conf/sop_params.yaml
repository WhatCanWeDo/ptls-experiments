data_module: 
  type: map
  setup: 
    col_id: customer_id
    dataset_files: 
      data_path: data/train_trx.parquet
    split_by: files
    valid_size: 0.05
    valid_split_seed: 42
  train: 
    min_seq_len: 25
    split_strategy: 
      split_strategy: SampleSlices
      split_count: 4
      cnt_min: 50
      cnt_max: 200
    augmentations: 
      - 
        - DropoutTrx
        - 
          trx_dropout: 0.01
    num_workers: 8
    batch_size: 256
  valid: 
    split_strategy: 
      split_strategy: SampleSlices
      split_count: 4
      cnt_min: 50
      cnt_max: 200
    augmentations: []
    num_workers: 16
    batch_size: 1024
seed_everything: 42
trainer: 
  gpus: 1
  auto_select_gpus: false
  max_epochs: 100
  deterministic: true
logger_name: sop_model
params: 
  data_module_class: ptls.data_load.data_module.sop_data_module.SopDataModuleTrain
  pl_module_class: ptls.lightning_modules.sop_nsp_module.SopNspModule
  encoder_type: rnn
  trx_encoder: 
    norm_embeddings: false
    embeddings_noise: 0.003
    embeddings: 
      mcc_code: 
        in: 200
        out: 48
      tr_type: 
        in: 100
        out: 24
    numeric_values: 
      amount: identity
  rnn: 
    type: gru
    hidden_size: 256
    bidir: false
    trainable_starter: static
  head: 
    hidden_size: 512
    drop_p: 0.5
    pred_all_states: false
  lr_scheduler: 
    ReduceLROnPlateau: true
    patience: 15
  train: 
    lr: 0.001
    weight_decay: 0.0
    use_best_epoch: true
model_path: ../../artifacts/scenario_gender/sop_model.p
inference_dataloader: 
  col_id: customer_id
  dataset_files: 
    - data/train_trx.parquet
    - data/test_trx.parquet
  SeqLenLimit: 
    max_seq_len: 1600
  loader: 
    num_workers: 4
    batch_size: 1000
output: 
  path: data/sop_embeddings
  format: pickle
